# Data-Leakage-Detection-in-Large-Language-Models-LLMs-
A framework for detecting data leakage and bias in LLMs (Llama-2, Mistral) using n-gram metrics and one-shot prompting. Analyzes model behavior on MMLU and TruthfulQA benchmarks to identify training data memorization and gender stereotyping patterns.
