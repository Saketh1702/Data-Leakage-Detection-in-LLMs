{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8448ea-184b-4a9a-82bf-88cda2e1dc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: huggingface_hub in ./.local/lib/python3.11/site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.11/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.11/site-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: packaging in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.local/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers torch huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29abc942-1ebe-4b0a-84ae-d3ca348d7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594548ee-5b56-4678-8123-d50637e458b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def mapping_to_letter(letter):\n",
    "    mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "    if letter in mapping:\n",
    "        return mapping[letter]\n",
    "\n",
    "def calculate_ngram_accuracy(reference, generated, n=2):\n",
    "    ref_ngrams = [reference[i:i+n] for i in range(len(reference) - n + 1)]\n",
    "    gen_ngrams = [generated[i:i+n] for i in range(len(generated) - n + 1)]\n",
    "    matches = len(set(ref_ngrams) & set(gen_ngrams))\n",
    "    return matches / len(ref_ngrams) if len(ref_ngrams) > 0 else 0.0\n",
    "\n",
    "# Function to synthesize benchmarks\n",
    "def synthesize_benchmarks(original_dataset, num_variants=3, perturb_rate=0.1):\n",
    "    synthesized_datasets = []\n",
    "    for _ in range(num_variants):\n",
    "        synthesized = []\n",
    "        for example in original_dataset:\n",
    "            # Perturb the choices by shuffling or masking a random word\n",
    "            choices = example[\"options\"].copy()\n",
    "            if random.random() < perturb_rate:\n",
    "                idx = random.randint(0, len(choices) - 1)\n",
    "                choices[idx] = \"[MASK]\"\n",
    "            synthesized.append({\"question\": example[\"question\"], \"options\": choices})\n",
    "        synthesized_datasets.append(synthesized)\n",
    "    return synthesized_datasets\n",
    "\n",
    "def detect_data_leakage(model, tokenizer, original_dataset, synthesized_datasets, n=2, device=\"cuda\"):\n",
    "    def generate_prediction(question, choices):\n",
    "        prompt = f\"Question: {question}\\nChoices: {', '.join(choices)}\\nAnswer:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)  # Move inputs to device\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=10)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Evaluate on original dataset\n",
    "    M_ori = []\n",
    "    for example in original_dataset:\n",
    "        predicted = generate_prediction(example[\"question\"], example[\"options\"])\n",
    "        correct = example[\"answer\"]\n",
    "        accuracy = calculate_ngram_accuracy(correct, predicted, n=n)\n",
    "        M_ori.append(accuracy)\n",
    "    M_ori = np.mean(M_ori)\n",
    "\n",
    "    # Evaluate on synthesized datasets\n",
    "    M_ref = []\n",
    "    for synthesized in synthesized_datasets:\n",
    "        synth_metrics = []\n",
    "        for example in synthesized:\n",
    "            predicted = generate_prediction(example[\"question\"], example[\"options\"])\n",
    "            correct = example[\"choices\"]  # Use the synthesized choices for comparison\n",
    "            accuracy = calculate_ngram_accuracy(correct, predicted, n=n)\n",
    "            synth_metrics.append(accuracy)\n",
    "        M_ref.append(np.mean(synth_metrics))\n",
    "    M_ref = np.mean(M_ref)\n",
    "\n",
    "    # Compute decrements\n",
    "    delta = M_ori - M_ref\n",
    "    delta_relative = (delta / M_ori) * 100\n",
    "    return M_ori, M_ref, delta, delta_relative\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the MMLU dataset\n",
    "    dataset = load_dataset(\"cais/mmlu\", \"anatomy\", split = \"test\")\n",
    "\n",
    "    # Select a small sample for testing\n",
    "    original_dataset = dataset.select(range(50))\n",
    "\n",
    "    # Transform the dataset to include only necessary columns\n",
    "    processed_dataset = []\n",
    "    for example in original_dataset:  # Access the dataset directly\n",
    "        question = example[\"question\"]\n",
    "        options = example[\"choices\"]\n",
    "        ans = mapping_to_letter(example[\"answer\"])\n",
    "        correct_index = ans  # Correct answer index\n",
    "        \n",
    "        # Mask one incorrect option randomly\n",
    "        incorrect_indices = [i for i in range(len(options)) if i != correct_index]\n",
    "        masked_index = random.choice(incorrect_indices)\n",
    "        masked_options = options.copy()\n",
    "        masked_options[masked_index] = \"[MASK]\"\n",
    "        \n",
    "        processed_dataset.append({\n",
    "            \"question\": question,\n",
    "            \"options\": options,\n",
    "            \"masked_options\": masked_options,\n",
    "            \"correct_index\": correct_index,\n",
    "            \"masked_index\": masked_index,\n",
    "        })\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "    model.to(\"cuda\")  # Move the model to GPU\n",
    "    model.eval()\n",
    "\n",
    "    # Generate synthesized benchmarks\n",
    "    synthesized_datasets = synthesize_benchmarks(processed_dataset, num_variants=3, perturb_rate=0.1)\n",
    "\n",
    "    # Detect data leakage\n",
    "    M_ori, M_ref, delta, delta_relative = detect_data_leakage(\n",
    "        model, tokenizer, processed_dataset, synthesized_datasets, n=2, device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    print(f\"Original Metric (M_ori): {M_ori:.4f}\")\n",
    "    print(f\"Synthesized Metric (M_ref): {M_ref:.4f}\")\n",
    "    print(f\"Decrement (Δ): {delta:.4f}\")\n",
    "    print(f\"Relative Decrement (δ): {delta_relative:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a93450-27e3-4503-9cc7-85acd2cca8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
