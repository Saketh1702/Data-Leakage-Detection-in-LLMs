{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f95df7-9bd0-49d3-9c01-a373de320379",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hugging face model and dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a26542-1722-420d-8e38-d11d16c69237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `Bleurt_token` has been saved to /home/bhora/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /home/bhora/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `Bleurt_token`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bac068a-416d-4899-845a-925d5c436218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cc8c14-690d-4e74-a34f-d6db6d58a8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "valid_dataset = load_dataset(\"SetFit/wnli\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5500a0fc-edae-4894-a133-8bb7e6032cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guided_prompt(test_instance):\n",
    "    # Extract information from the instance\n",
    "    text1 = test_instance['text1']\n",
    "    text2 = test_instance['text2']\n",
    "    label = test_instance['label']\n",
    "    label_text = test_instance['label_text']\n",
    "    \n",
    "    # Format the prompt with the provided instance\n",
    "    guided_prompt = f'''Instruction: An instance in the WNLI dataset has 2 Sentences and a label. You are provided with Sentence 1 from\n",
    "an instance of the WNLI dataset. Finish Sentence 2 exactly as it appears in the dataset. \n",
    "Example 1:\n",
    "Sentence 1: John couldn't see the stage with Billy in front of him because he is so short.\n",
    "Label: 1 (entailment)\n",
    "Sentence 2: John is so short.\n",
    "\n",
    "Example 2:\n",
    "Sentence 1: The table won't fit through the doorway because it is too narrow.\n",
    "Label: 0 (not entailment)\n",
    "Sentence 2: The table is too narrow.\n",
    "###\n",
    "Now, Finish sentence 2:\n",
    "Sentence 1: {text1}\n",
    "Label: {label} ({label_text})\n",
    "Sentence 2:'''\n",
    "\n",
    "    return guided_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c948bc7-f002-40e0-9480-bf2a297e5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_general_prompt(test_instance):\n",
    "    text1 = test_instance['text1']\n",
    "    text2 = test_instance['text2']\n",
    "    label = test_instance['label']\n",
    "    label_text = test_instance['label_text']\n",
    "    \n",
    "    general_prompt = f'''Instruction: Finish Sentence 2 based on Sentence 1,\n",
    "such that the following label shows the logical relationship between Sentence 1 and Sentence 2. Understand both examples and finish sentence 2.\n",
    "\n",
    "Example 1:\n",
    "Sentence 1: John couldn't see the stage with Billy in front of him because he is so short.\n",
    "Label: 1 (entailment)\n",
    "Sentence 2: John is so short.\n",
    "\n",
    "Example 2:\n",
    "Sentence 1: The table won't fit through the doorway because it is too narrow.\n",
    "Label: 0 (not entailment)\n",
    "Sentence 2: The table is too narrow.\n",
    "\n",
    "####\n",
    "Now, Finish sentence 2\n",
    "Sentence 1: {text1}\n",
    "Label: {label} ({label_text})\n",
    "Sentence 2:'''\n",
    "\n",
    "    return general_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c8d5051-49f4-493c-aa38-99fcbb8e99ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1': 'George got free tickets to the play, but he gave them to Eric, because he was not particularly eager to see it.',\n",
       " 'text2': 'Eric was not particularly eager to see it.',\n",
       " 'label': 0,\n",
       " 'idx': 70,\n",
       " 'label_text': 'not entailment'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e808b2f8-4632-40f7-883e-623c943e9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Finish Sentence 2 based on Sentence 1,\n",
      "such that the following label shows the logical relationship between Sentence 1 and Sentence 2. Understand both examples and finish sentence 2.\n",
      "\n",
      "Example 1:\n",
      "Sentence 1: John couldn't see the stage with Billy in front of him because he is so short.\n",
      "Label: 1 (entailment)\n",
      "Sentence 2: John is so short.\n",
      "\n",
      "Example 2:\n",
      "Sentence 1: The table won't fit through the doorway because it is too narrow.\n",
      "Label: 0 (not entailment)\n",
      "Sentence 2: The table is too narrow.\n",
      "\n",
      "####\n",
      "Now, Finish sentence 2\n",
      "Sentence 1: The drain is clogged with hair. It has to be cleaned.\n",
      "Label: 0 (not entailment)\n",
      "Sentence 2:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate the guided prompt\n",
    "generated_prompt = generate_general_prompt(valid_dataset[0])\n",
    "\n",
    "# Print the result\n",
    "print(generated_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155fe1cf-a79e-456c-8b27-6db13d0cff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_last_sentence_2_from_generated_output(text):\n",
    "    # Regular expression to match all occurrences of \"Sentence 2:\" and capture the following sentence\n",
    "    matches = re.findall(r'Sentence 2: (.*?)(?=\\n|$)', text, re.DOTALL)\n",
    "    \n",
    "    # If there are any matches, return the last one (which is the last \"Sentence 2\")\n",
    "    if matches:\n",
    "        last_sentence_2 = matches[-1].strip()  # Get the last matched sentence and strip extra spaces\n",
    "        # Ensure that we capture the sentence up to the full stop (period)\n",
    "        return last_sentence_2.split('.')[0] + '.'  # Add period at the end if not there\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a61b2e3e-5d2b-4cf7-ad88-468bf28eb57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.local/lib/python3.11/site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from evaluate) (1.26.0)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from evaluate) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.11/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from evaluate) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.local/lib/python3.11/site-packages (from evaluate) (0.26.3)\n",
      "Requirement already satisfied: packaging in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8549444f-57fb-4352-b599-d0314d70f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rouge_score in ./.local/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.11/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: numpy in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from rouge_score) (1.26.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.local/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.11/site-packages (from nltk) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0cf462c-d48a-479d-88a7-59cdf8b773df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.local/lib/python3.11/site-packages (from accelerate) (0.26.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.11/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.local/lib/python3.11/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: networkx in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /packages/apps/jupyter/2023-10-09/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d7dcf0-117f-4298-a2f5-a20cc94a84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e954ea0-ba5f-4481-a44f-aae8cde873d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cb9bd9a4e240838dcb4cb0b8ed4a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7eefe772c954458a4f1e588881a255e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af7a12ef9f44c33bfc27a889f49d6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b02b15f94c4e1ebc30a6a7b5607883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74191bb9632545a09b7eab0499111255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fce240f3e443ec93638e4d8be31e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddf71b518b84a37b879e140d607e3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c65333cef524d2a9336fbd61953950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f63110c3c84b989ed0a40fcf921002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-hf\",device_map = 'auto', torch_dtype = torch.float16)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e10f86-4898-4ba6-ba2f-3dd644ec59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleurt_tokenizer = AutoTokenizer.from_pretrained(\"Elron/bleurt-base-128\")\n",
    "bleurt_model = AutoModelForSequenceClassification.from_pretrained(\"Elron/bleurt-base-128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1a8eb-a2fe-437a-a770-b0a0455dc86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e5dd8-dde0-4767-beef-dab25be3e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleurt_score(reference, candidate):\n",
    "    inputs = bleurt_tokenizer(reference, candidate, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        score = bleurt_model(**inputs).logits\n",
    "    return score.item()\n",
    "\n",
    "def compute_rouge_l(reference, candidate):\n",
    "    scores = rouge.compute(predictions=[candidate], references=[reference])\n",
    "    ##return scores['rougeL'].mid.fmeasure\n",
    "    ##print(scores)  # Print the structure of the scores to debug\n",
    "    return scores['rougeL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98470d80-b7b7-4d16-82ba-f00d0cb932f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now model for loop setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81cad8-49bb-4024-9192-20991f0163e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_guided_bleurt=0\n",
    "avg_general_bleurt=0\n",
    "avg_guided_rouge=0\n",
    "avg_general_rouge=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21268e7f-9867-40e9-a9e5-733c08accc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_instances = 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f72fad-72ef-457d-9d01-4c2506d27f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total_instances):\n",
    "    # Generate the prompt for the guided test instance\n",
    "    test_instance = valid_dataset[i]\n",
    "    guided_prompt = generate_guided_prompt(test_instance)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Tokenize the prompt and pass it to the model\n",
    "    inputs = tokenizer(guided_prompt, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids, \n",
    "        max_new_tokens=50,  # Or however many tokens you expect\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id  # Ensure padding is handled correctly\n",
    "    )\n",
    "\n",
    "    # Decode and print the model's output\n",
    "    guided_generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    guided_output = extract_last_sentence_2_from_generated_output(guided_generated_text)\n",
    "    \n",
    "    print(f\"Output for guided instance {i+1}:\\n{guided_output}\\n\")\n",
    "######### now calculate for general prompt\n",
    "    \n",
    "    general_prompt = generate_general_prompt(test_instance)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # Tokenize the prompt and pass it to the model\n",
    "    inputs = tokenizer(general_prompt, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids, \n",
    "        max_new_tokens=50,  # Or however many tokens you expect\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id  # Ensure padding is handled correctly\n",
    "    )\n",
    "\n",
    "    # Decode and print the model's output\n",
    "    general_generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    general_output = extract_last_sentence_2_from_generated_output(general_generated_text)\n",
    "\n",
    "    print(f\"Output for general instance {i+1}:\\n{general_output}\\n\")\n",
    "\n",
    "    ### both general and guided prompts output generated\n",
    "    dataset_line = test_instance['text2']\n",
    "    print(\"Original line: \", dataset_line)\n",
    "    guided_bleurt = compute_bleurt_score(dataset_line, guided_output)\n",
    "    general_bleurt = compute_bleurt_score(dataset_line, general_output)\n",
    "    guided_rouge_l = compute_rouge_l(dataset_line, guided_output)\n",
    "    general_rouge_l = compute_rouge_l(dataset_line, general_output)\n",
    "\n",
    "    avg_guided_bleurt+=guided_bleurt\n",
    "    avg_general_bleurt=general_bleurt\n",
    "    avg_guided_rouge+=guided_rouge_l\n",
    "    avg_general_rouge+=general_rouge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02929b4-83e7-4543-8ba1-096bd7628813",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_guided_bleurt/=total_instances\n",
    "avg_general_bleurt/=total_instances\n",
    "avg_guided_rouge/=total_instances\n",
    "avg_general_rouge/=total_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89c1e5-c21b-4ab8-9ae4-37f27085e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average guided Bleurt score : \",avg_guided_bleurt)\n",
    "print(\"Average guided RougeL score : \",avg_guided_rouge)\n",
    "print(\"Average general Bleurt score : \",avg_general_bleurt)\n",
    "print(\"Average general RougeL score : \",avg_general_rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956924a-9b65-4b89-b6b9-2b86b46d99df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
